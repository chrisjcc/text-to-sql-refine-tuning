# Core
torch>=2.1.0
transformers>=4.36.0
datasets>=2.14.0
accelerate>=0.25.0
trl>=0.7.0
peft>=0.7.0
bitsandbytes>=0.41.0

# Verifiers
verifiers>=0.1.0

# Configuration & Logging
hydra-core>=1.3.0
omegaconf>=2.3.0
python-dotenv>=1.0.0
wandb>=0.16.0

# SQL & Evaluation
sqlparse>=0.4.4

# Utilities
numpy>=1.24.0
pandas>=2.0.0
tqdm>=4.66.0

# API
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0

# CLI
rich>=13.6.0

# Testing
pytest>=7.4.0
pytest-cov>=4.1.0

# Flash Attention (optional but recommended)
# Requires specific CUDA version
# Install with: pip install flash-attn --no-build-isolation
# flash-attn>=2.3.0
